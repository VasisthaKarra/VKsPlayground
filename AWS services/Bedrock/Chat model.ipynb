{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f32ec1e",
   "metadata": {},
   "source": [
    "# Initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb238cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# If necessary, replace us-west-2 with the AWS Region you're using for Amazon SES.\n",
    "AWS_REGION = \"us-east-1\"\n",
    "\n",
    "brt = boto3.client(service_name='bedrock-runtime',region_name=AWS_REGION)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4859662",
   "metadata": {},
   "source": [
    "# Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ae86fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = json.dumps({\n",
    "    \"prompt\": \"\\n\\nHuman:explain black holes to 8th graders\\n\\nAssistant:\",\n",
    "    \"max_tokens_to_sample\": 300,\n",
    "    \"temperature\": 0.1,\n",
    "    \"top_p\": 0.9,\n",
    "})\n",
    "\n",
    "modelId = 'anthropic.claude-instant-v1'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e56e285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is how I would explain black holes to 8th graders:\n",
      "\n",
      "A black hole is a place in space where gravity is so strong that nothing, not even light, can escape from it. It forms when a very massive star dies and collapses in on itself. \n",
      "\n",
      "Imagine you have a giant ball of gas that is many times more massive than our sun. This ball of gas is the core of a very massive star. As the star is burning its nuclear fuel, it is pushing against its own gravity with the heat and pressure from its nuclear fusion reactions in its core. \n",
      "\n",
      "But eventually, the star runs out of fuel. When it does, there is nothing left to push against the incredible force of gravity from all that mass. Gravity takes over and starts crushing the core of the star inward. The more it collapses, the stronger the gravitational pull becomes. \n",
      "\n",
      "It gets crushed so incredibly small and dense that the escape velocity needed to get away from it exceeds the speed of light! Anything that comes too close, even light itself, gets pulled into the black hole never to return. Not even light can escape once it crosses the \"event horizon,\" which is the point of no return around a black hole.\n",
      "\n",
      "We can't see a black hole directly because not even light can escape it. But we know they are there because of their intense gravity. Black holes can pull material away from nearby stars and grow larger over time by \"feeding.\"\n"
     ]
    }
   ],
   "source": [
    "response = brt.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "# text\n",
    "print(response_body.get('completion'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27db9ce",
   "metadata": {},
   "source": [
    "# A2I Jurassic-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b8820a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = json.dumps({\n",
    "    \"prompt\": \"Translate to spanish: 'Amazon Bedrock is the easiest way to build and scale generative AI applications with base models (FMs)'.\", \n",
    "    \"maxTokens\": 200,\n",
    "    \"temperature\": 0.5,\n",
    "    \"topP\": 0.5\n",
    "})\n",
    "\n",
    "modelId = 'ai21.j2-mid-v1'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a021cd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'Amazon Bedrock es la manera más fácil de construir y escalado de aplicaciones generativas de IA con modelos base (FMs)'.\n"
     ]
    }
   ],
   "source": [
    "response = brt.invoke_model(\n",
    "    body=body, \n",
    "    modelId=modelId, \n",
    "    accept=accept, \n",
    "    contentType=contentType\n",
    ")\n",
    "\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "# text\n",
    "print(response_body.get('completions')[0].get('data').get('text'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b19ea6c",
   "metadata": {},
   "source": [
    "# Cohere Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "473fb517",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = json.dumps({\n",
    "    \"prompt\": \"How do you tie a tie?\", \n",
    "    \"max_tokens\": 200,\n",
    "    \"temperature\": 0.5,\n",
    "    \"p\": 0.5\n",
    "})\n",
    "\n",
    "modelId = 'cohere.command-text-v14'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bf934d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here are the steps to tie a tie:\n",
      "\n",
      "1. Place the tie around your neck with the wide end on the right side and the narrow end on the left side. The wide end should be about 1 foot longer than the narrow end.\n",
      "2. Cross the wide end over the narrow end and place it over the narrow end.\n",
      "3. Take the wide end and place it under the narrow end.\n",
      "4. Bring the wide end back over the narrow end and place it over the narrow end again.\n",
      "5. Take the wide end and place it under the narrow end, but this time, pull it all the way through.\n",
      "6. Bring the wide end up and around the knot and pull it down.\n",
      "7. Pull the wide end through the loop and pull it tight.\n",
      "8. Adjust the knot and the length of the tie to your liking.\n",
      "\n",
      "These steps should help you tie a tie correctly. If you have any questions or need more help\n"
     ]
    }
   ],
   "source": [
    "response = brt.invoke_model(\n",
    "    body=body, \n",
    "    modelId=modelId, \n",
    "    accept=accept, \n",
    "    contentType=contentType\n",
    ")\n",
    "\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "# text\n",
    "print(response_body.get('generations')[0].get('text'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d973cb6",
   "metadata": {},
   "source": [
    "# Meta Llama 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a423da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = json.dumps({\n",
    "    \"prompt\": \"What is the average lifespan of a Llama?\",\n",
    "    \"max_gen_len\": 128,\n",
    "    \"temperature\": 0.1,\n",
    "    \"top_p\": 0.9,\n",
    "})\n",
    "\n",
    "modelId = 'meta.llama2-13b-chat-v1'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76c0b5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generation': \"\\n\\nThe average lifespan of a llama is 15 to 25 years, with some individuals living up to 30 years or more. Factors such as breed, living conditions, and health can affect a llama's lifespan.\", 'prompt_token_count': 14, 'generation_token_count': 58, 'stop_reason': 'stop'}\n"
     ]
    }
   ],
   "source": [
    "response = brt.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "\n",
    "response_body = json.loads(response.get('body').read())\n",
    "print(response_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485e7fd7",
   "metadata": {},
   "source": [
    "# Stability AI Diffusion XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa71e338",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_data = \"A photograph of an dog on the top of a mountain covered in snow.\"\n",
    "\n",
    "body = json.dumps({\n",
    "  \"text_prompts\": [\n",
    "    { \n",
    "      \"text\": prompt_data \n",
    "    }\n",
    "  ],\n",
    "  \"cfg_scale\":10,\n",
    "  \"seed\":20,\n",
    "  \"steps\":50\n",
    "})\n",
    "modelId = \"stability.stable-diffusion-xl-v0\" \n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fe15c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n",
      "iVBORw0KGgoAAAANSUhEUgAAAgAAAAIACAIAAAB7GkOtAAAB0mVYSWZNTQAqAAAACAAGAQAABAAAAAEA...\n"
     ]
    }
   ],
   "source": [
    "response = brt.invoke_model(\n",
    "    body=body, \n",
    "    modelId=modelId, \n",
    "    accept=accept, \n",
    "    contentType=contentType\n",
    ")\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "print(response_body['result'])\n",
    "print(f'{response_body.get(\"artifacts\")[0].get(\"base64\")[0:80]}...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f57fc67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
